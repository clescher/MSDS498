{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Data Prep Master.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/clescher/MSDS498/blob/master/Data%20Prep%20Master.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NamLaJvgyatY"
      },
      "source": [
        "## EDA and data preparation code development\n",
        "\n",
        "### Northwestern Banking\n",
        "\n",
        "#### Loan prediction project\n",
        "##### Updated 11-02-2020 Strouse"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4L4Dyeh8yatZ"
      },
      "source": [
        "# Initiate Libraries\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import datetime\n",
        "import os\n",
        "import io\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "assAvVpu4dK2"
      },
      "source": [
        "COLAB CODE\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "URj7ZKmy4PXz",
        "outputId": "a5e61c6f-ebbf-4c9a-ed19-3833383179a5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FO_xKs5_z0Q3"
      },
      "source": [
        "#collab code\n",
        "#from google.colab import files\n",
        "#uploaded = files.upload()\n",
        "#df = pd.read_csv(io.BytesIO(uploaded['smallerdata.csv']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h0_tmq5kyatd"
      },
      "source": [
        "#desktop code\n",
        "#datapath = os.path\n",
        "#df = pd.read_csv(\"smallerdata.csv\",  sep=',')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Zue356fyatg"
      },
      "source": [
        "### Declare all Functions here"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "39IdnnAcyath"
      },
      "source": [
        "#a function that receives the dataframe, data column & row you wish to alter a string into a date format\n",
        "def dateconvert(datestring):\n",
        "\n",
        "    #empty \n",
        "    if type(datestring) == float:\n",
        "        year = \"1900\"\n",
        "        month = \"Jan\"\n",
        "    #3-Jan for 01/01/2003\n",
        "    elif len(datestring)==5:\n",
        "        year = \"200\" + datestring[0:1]\n",
        "        month = datestring[2:5]\n",
        "    #19-Mar for 03/01/2019\n",
        "    elif datestring[0:2].isnumeric():\n",
        "        year = datestring[0:2]\n",
        "        month = datestring[3:6]\n",
        "    #Feb-2000 for 02/01/2000    \n",
        "    elif datestring[4:8].isnumeric() and len (datestring[4:8])==4:\n",
        "        month = datestring[0:3]\n",
        "        year = datestring[4:8]\n",
        "    #Feb-01 for 02/01/2019\n",
        "    elif datestring[4:8].isnumeric() and len (datestring[4:8])==2:\n",
        "        month = datestring[0:3]\n",
        "        year = datestring[4:6]\n",
        "    \n",
        "    #this is a manual process to convert 2 year dates to 4 since the automatic one doesn't work\n",
        "    if len(year)==2:\n",
        "        if int(year) < 21:\n",
        "            year=\"20\"+year\n",
        "        else:\n",
        "            year = \"19\"+year\n",
        "    \n",
        "    date_time_str = month +' 01 '+ year\n",
        "    #all dates have to be forced to a 4 year, otherwise we get like 2065 as dates\n",
        "    date_time_obj = datetime.datetime.strptime(date_time_str, '%b %d %Y')\n",
        "    \n",
        "    return date_time_obj"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qMjd7HZCyatj"
      },
      "source": [
        "###  Data Cleaning Code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Z5j6zmlyatk"
      },
      "source": [
        "#### id"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5sttK-Iyyatk"
      },
      "source": [
        "#removes those wierd summary rows as they all contain the word \"amount\" in the id column\n",
        "#converts ID to string to then search it, then changes it back to integer to ensure no issues\n",
        "df['id']=df['id'].astype(str)\n",
        "df = df[~df['id'].str.contains(\"amount\")]\n",
        "df['id']=df['id'].astype(np.int32)\n",
        "#resets the index in order so further coding can be easier\n",
        "df = df.reset_index(drop=True)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FEoTOo4cyatn"
      },
      "source": [
        "#### Date related columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4XZCbQhyatn"
      },
      "source": [
        "#add the column headers you need to this date converting list\n",
        "datecol_list = ['issue_d','earliest_cr_line','last_pymnt_d','last_credit_pull_d',\n",
        "                'hardship_start_date','hardship_end_date','payment_plan_start_date',\n",
        "                'debt_settlement_flag_date','settlement_date']\n",
        "\n",
        "#loops the date columns through the dateconvert function and creates new columns with a \"2\" at the end\n",
        "for c in range(0,len(datecol_list)):\n",
        "    df[datecol_list[c]+\"2\"] = df.apply(lambda x: dateconvert(x[datecol_list[c]]), axis =1)\n",
        "    df[datecol_list[c]+\"2\"] = pd.to_datetime(df[datecol_list[c]+\"2\"])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZCDZUvVyatq"
      },
      "source": [
        "#### int_rate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GrqBXmtlyatq"
      },
      "source": [
        "# convert 'int_rate' to string\n",
        "df['int_rate']=df['int_rate'].astype(str)\n",
        "# strip off % sign and convert to float\n",
        "df['int_rate'] = df['int_rate'].str.rstrip('%').astype('float') / 100.0"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "802akcTsyatt"
      },
      "source": [
        "#### revol_util"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mMzPbmaWyatt"
      },
      "source": [
        "# convert 'revol_util' to string\n",
        "df['revol_util']=df['revol_util'].astype(str)\n",
        "# strip off % sign and convert to float\n",
        "df['revol_util'] = df['revol_util'].str.rstrip('%').astype('float') / 100.0"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7YjOC7d-yatw"
      },
      "source": [
        "## Feature Generation & Transformations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCvIdU7Kyatw"
      },
      "source": [
        "#### len_credit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T2FF599pyatw"
      },
      "source": [
        "#calculates the length of credit they've had in years\n",
        "df['len_credit'] = pd.to_numeric((df['issue_d2']-df['earliest_cr_line2']).dt.days)/365"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xd9Neb3kyaty"
      },
      "source": [
        "#### max_fico_high"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5KbObHZyatz"
      },
      "source": [
        "df['max_fico_high']= df[[\"fico_range_high\", \"sec_app_fico_range_high\"]].max(axis=1)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zSYNHIxEyat1"
      },
      "source": [
        "#### max_fico_low"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sMOAV3Uxyat1"
      },
      "source": [
        "df['max_fico_low']= df[[\"fico_range_low\", \"sec_app_fico_range_low\"]].max(axis=1)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZQkiIEIyat4"
      },
      "source": [
        "#### delinq_amt_pct "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HIGztWKhyat4"
      },
      "source": [
        "df['delinq_amt_pct']=(df['delinq_amnt']/df['total_bal_ex_mort'])\n",
        "df.loc[df['delinq_amt_pct']> 1, 'delinq_amt_pct'] = 1"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2hIV6S8Zyat6"
      },
      "source": [
        "#### sats_pct "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uG-QyEuGyat7"
      },
      "source": [
        "df['sats_pct']=(df['num_sats']/df['open_acc'])"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KYDPyZuQyat9"
      },
      "source": [
        "#### emp_length2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WsFA7i4nyat9"
      },
      "source": [
        "#converts employment lengt to a number (imputes 0 years for null)\n",
        "df['emp_length2'] = df['emp_length'].str[0:1]\n",
        "df.loc[df['emp_length']==\"< 1 year\", 'emp_length2'] = \"0\"\n",
        "df.loc[df['emp_length']==\"10+ years\", 'emp_length2'] = \">\"\n",
        "df.loc[df['emp_length2']==\">\", 'emp_length2'] = \"10\"\n",
        "df.loc[df['emp_length'].isnull(), 'emp_length2'] = \"0\"\n",
        "df['emp_length2']=df['emp_length2'].astype(int)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PLHiEGxXyat_"
      },
      "source": [
        "#### initial_list_status (create dummy)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nTIvl71PyauA"
      },
      "source": [
        "df.loc[df['initial_list_status']==\"w\", 'initial_list_status2'] = 0\n",
        "df.loc[df['initial_list_status']==\"f\", 'initial_list_status2'] = 1"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TUNIRNNayauB"
      },
      "source": [
        "#### hardship_flag"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oqqy1SXOyauC"
      },
      "source": [
        "df.loc[df['hardship_flag']==\"N\", 'hardship_flag2'] = 0\n",
        "df.loc[df['hardship_flag']==\"Y\", 'hardship_flag2'] = 1"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pAkuQS7ZyauD"
      },
      "source": [
        "#### home_ownership"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZLJcanWyauE"
      },
      "source": [
        "df['home_ownership2'] = 0\n",
        "df.loc[df['home_ownership']==\"RENT\", 'home_ownership2'] = 1\n",
        "df.loc[df['home_ownership']==\"OWN\", 'home_ownership2'] = 2\n",
        "df.loc[df['home_ownership']==\"MORTGAGE\", 'home_ownership2'] = 2"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uOd80rPLyauF"
      },
      "source": [
        "#### desc"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3CrmvbiByauG"
      },
      "source": [
        "df['desc2'] = 1\n",
        "df.loc[df['desc'].isnull(), 'desc2'] = 0"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kO7GqXMYyauH"
      },
      "source": [
        "#### verification_status"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uYK2QPjFyauI"
      },
      "source": [
        "df.loc[df['verification_status']==\"Not Verified\", 'verification_status2'] = 0\n",
        "df.loc[df['verification_status']==\"Verified\", 'verification_status2'] = 1\n",
        "df.loc[df['verification_status']==\"Source Verified\", 'verification_status2'] = 1"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5pajV9oUyauJ"
      },
      "source": [
        "#### pymnt_plan"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48YVL3biyauK"
      },
      "source": [
        "df.loc[df['pymnt_plan']==\"n\", 'pymnt_plan2'] = 0\n",
        "df.loc[df['pymnt_plan']==\"y\", 'pymnt_plan2'] = 1"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D9Ytn4r06KV6"
      },
      "source": [
        "#### default_ind"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KRhtniV0yauN"
      },
      "source": [
        "#creates binary indicator for defaulted or not\n",
        "#just an error checker to ensure that all statuses are accounted for\n",
        "df['default_ind']=2\n",
        "#should be a lsit of all good status loans\n",
        "df.loc[(df['loan_status'] == 'Fully Paid'), 'default_ind'] = 0\n",
        "#should be a list of all defaulted loans\n",
        "df.loc[(df['loan_status'] == 'Charged Off'), 'default_ind'] = 1"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0wOGUOg3yauN"
      },
      "source": [
        "#### Variable transformations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UraSE9BBs009"
      },
      "source": [
        "#### loan_amnt_cuberoot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_UNMCDnH6VW3"
      },
      "source": [
        "#Loan Amnt Cube Root Transform\n",
        "df['loan_amnt_cuberoot']=np.power(np.sign(df['loan_amnt']) * np.abs(df['loan_amnt']),1/3)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wKgNRJkhs00_"
      },
      "source": [
        "#### int_rate_log"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pTvy4HPLCQF4"
      },
      "source": [
        "#Int Rate Log Transform\n",
        "df['int_rate_log']=np.log10(df['int_rate'])"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qdmST34qs01B"
      },
      "source": [
        "#### len_credit_cuberoot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zeyiHg0dDhPA"
      },
      "source": [
        "#Len Credit Cube Root Transform\n",
        "df['len_credit_cuberoot']=np.power(np.sign(df['len_credit']) * np.abs(df['len_credit']),1/3)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5lUyNgAD0Snu"
      },
      "source": [
        "#### annual_inc Row drop and transform\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q2FKcnfx0isH"
      },
      "source": [
        "#Row Drop for incomes above 400,000\n",
        "df = df[df['annual_inc'] <= 400000]"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PDu2SKwD1CSf"
      },
      "source": [
        "#Cube Transform\n",
        "df['annual_inc_cuberoot']=np.power(np.sign(df['annual_inc']) * np.abs(df['annual_inc']),1/3)\n"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hz7SodnTyauR"
      },
      "source": [
        "#### convert blanks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7J4ZT6PoyauR"
      },
      "source": [
        "#convert blanks to NA\n",
        "df['dti'].replace('', np.nan, inplace=True)\n",
        "df['revol_util'].replace('', np.nan, inplace=True)\n",
        "df['tot_coll_amt'].replace('', np.nan, inplace=True)\n",
        "df['delinq_amt_pct'].replace('', np.nan, inplace=True)\n",
        "df['pct_tl_nvr_dlq'].replace('', np.nan, inplace=True)\n",
        "df['pub_rec_bankruptcies'].replace('', np.nan, inplace=True)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "762iPxxvyauU"
      },
      "source": [
        "#### bad dates"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ti7QlA_lyauU"
      },
      "source": [
        "#removes rows with empty dates as they were all set to 01/01/1990\n",
        "df=df[(df['issue_d2']!=\"1900-01-01\") | (df['earliest_cr_line2']!=\"1900-01-01\")]"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2C72tghPUd6U"
      },
      "source": [
        "#### DTI Fix N/A and Cube Transform"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eh_qYnX9UnIT"
      },
      "source": [
        "#Fix data issues with N/A's\n",
        "#df['dti'].isna().sum()\n",
        "#257 missing N/A values\n",
        "df['dti']=df['dti'].replace(np.nan,0)\n",
        "#df['dti'].isna().sum()\n",
        "#0 Nulls left\n"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5h-FKCifXBVC"
      },
      "source": [
        "#Cube Transform of DTI\n",
        "df['dti_cube']=np.power(np.sign(df['dti']) * np.abs(df['dti']),1/3)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_o-p4eQWyauW"
      },
      "source": [
        "#### Modeling data set creation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IZBvJhDWsycP"
      },
      "source": [
        "### binary model dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFXsG4omyauW"
      },
      "source": [
        "#keep only columns we need\n",
        "modeldf = df[['id', 'default_ind', 'loan_amnt_cuberoot', 'term', 'int_rate_log', 'grade', \n",
        "              'emp_length2', 'home_ownership2', \n",
        "              'desc2', 'purpose', 'dti_cube', 'delinq_2yrs', \n",
        "              'revol_util', 'initial_list_status2', 'application_type', \n",
        "              'tot_coll_amt', 'chargeoff_within_12_mths', 'pct_tl_nvr_dlq', 'pub_rec_bankruptcies', \n",
        "              'total_bal_ex_mort', 'delinq_amt_pct', \n",
        "              'sats_pct', 'max_fico_low','len_credit_cuberoot','annual_inc_cuberoot' ]]\n",
        "\n",
        "modeldf=modeldf.dropna()\n",
        "modeldf = modeldf.reset_index(drop=True)\n"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YaXLcMHIyauZ"
      },
      "source": [
        "#save files\n",
        "modeldf.to_csv('modelingdftrain.csv')  "
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UeOsBRrrsycT"
      },
      "source": [
        "### value model dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FBKo5H3xsycT"
      },
      "source": [
        "#keep only columns we need\n",
        "modeldf = df[['id', 'default_ind', 'total_pymnt', 'loan_amnt_cuberoot', 'term', 'int_rate_log', 'grade', \n",
        "              'emp_length2', 'home_ownership2', \n",
        "              'desc2', 'purpose', 'dti_cube', 'delinq_2yrs', \n",
        "              'revol_util', 'initial_list_status2', 'application_type', \n",
        "              'tot_coll_amt', 'chargeoff_within_12_mths', 'pct_tl_nvr_dlq', 'pub_rec_bankruptcies', \n",
        "              'total_bal_ex_mort', 'delinq_amt_pct', \n",
        "              'sats_pct', 'max_fico_low','len_credit_cuberoot','annual_inc_cuberoot' ]]\n",
        "\n",
        "modeldf = modeldf[modeldf['default_ind'] == 1]\n",
        "modeldf.drop(['default_ind'], axis=1)\n",
        "modeldf=modeldf.dropna()\n",
        "modeldf = modeldf.reset_index(drop=True)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uBGhcJnXsycV"
      },
      "source": [
        "#save files\n",
        "modeldf.to_csv('modelingdfvalue.csv')  "
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aY2as5rZyYZz"
      },
      "source": [
        "### Dashboard specific data to merge on"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OcKdy889yYZ0"
      },
      "source": [
        "#keep only columns we need\n",
        "modeldf = df[['id', 'total_pymnt', 'term', 'int_rate', 'grade', 'emp_length2', \n",
        "                     'home_ownership2', 'annual_inc', 'desc2', 'purpose', 'dti', 'delinq_2yrs', \n",
        "                     'revol_util', 'pub_rec_bankruptcies', 'len_credit', 'funded_amnt']]\n",
        "\n",
        "modeldf=modeldf.dropna()\n",
        "modeldf = modeldf.reset_index(drop=True)\n"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LFvIp8d4yYZ1"
      },
      "source": [
        "#save files\n",
        "modeldf.to_csv('dashboardmerger.csv')  "
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ANNWevuJyYZ3"
      },
      "source": [
        ""
      ],
      "execution_count": 37,
      "outputs": []
    }
  ]
}