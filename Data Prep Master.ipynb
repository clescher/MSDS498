{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "Data Prep Master.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/clescher/MSDS498/blob/logan/Data%20Prep%20Master.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NamLaJvgyatY"
      },
      "source": [
        "## EDA and data preparation code development\n",
        "\n",
        "### Northwestern Banking\n",
        "\n",
        "#### Loan prediction project\n",
        "##### Updated 10-10-2020 Lescher"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4L4Dyeh8yatZ"
      },
      "source": [
        "# Initiate Libraries\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import datetime\n",
        "import os\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h0_tmq5kyatd",
        "outputId": "b0c3326b-dd9d-4864-85da-9ab74763dcd5"
      },
      "source": [
        "# Import CSV\n",
        "datapath = os.path\n",
        "df = pd.read_csv(\"smallerdata.csv\",  sep=',')\n",
        "# df = pd.read_excel(\"smallerdata.csv\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\clesc\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3071: DtypeWarning: Columns (7,20,36,60,119,130,131,132,135,136,137,140) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Zue356fyatg"
      },
      "source": [
        "### Declare all Functions here"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "39IdnnAcyath"
      },
      "source": [
        "#a function that receives the dataframe, data column & row you wish to alter a string into a date format\n",
        "def dateconvert(datestring):\n",
        "\n",
        "    #empty \n",
        "    if type(datestring) == float:\n",
        "        year = \"1900\"\n",
        "        month = \"Jan\"\n",
        "    #3-Jan for 01/01/2003\n",
        "    elif len(datestring)==5:\n",
        "        year = \"200\" + datestring[0:1]\n",
        "        month = datestring[2:5]\n",
        "    #19-Mar for 03/01/2019\n",
        "    elif datestring[0:2].isnumeric():\n",
        "        year = datestring[0:2]\n",
        "        month = datestring[3:6]\n",
        "    #Feb-2000 for 02/01/2000    \n",
        "    elif datestring[4:8].isnumeric() and len (datestring[4:8])==4:\n",
        "        month = datestring[0:3]\n",
        "        year = datestring[4:8]\n",
        "    #Feb-01 for 02/01/2019\n",
        "    elif datestring[4:8].isnumeric() and len (datestring[4:8])==2:\n",
        "        month = datestring[0:3]\n",
        "        year = datestring[4:6]\n",
        "    \n",
        "    #this is a manual process to convert 2 year dates to 4 since the automatic one doesn't work\n",
        "    if len(year)==2:\n",
        "        if int(year) < 21:\n",
        "            year=\"20\"+year\n",
        "        else:\n",
        "            year = \"19\"+year\n",
        "    \n",
        "    date_time_str = month +' 01 '+ year\n",
        "    #all dates have to be forced to a 4 year, otherwise we get like 2065 as dates\n",
        "    date_time_obj = datetime.datetime.strptime(date_time_str, '%b %d %Y')\n",
        "    \n",
        "    return date_time_obj"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qMjd7HZCyatj"
      },
      "source": [
        "###  Data Cleaning Code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Z5j6zmlyatk"
      },
      "source": [
        "#### id"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5sttK-Iyyatk"
      },
      "source": [
        "#removes those wierd summary rows as they all contain the word \"amount\" in the id column\n",
        "#converts ID to string to then search it, then changes it back to integer to ensure no issues\n",
        "df['id']=df['id'].astype(str)\n",
        "df = df[~df['id'].str.contains(\"amount\")]\n",
        "df['id']=df['id'].astype(np.int32)\n",
        "#resets the index in order so further coding can be easier\n",
        "df = df.reset_index(drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FEoTOo4cyatn"
      },
      "source": [
        "#### Date related columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4XZCbQhyatn"
      },
      "source": [
        "#add the column headers you need to this date converting list\n",
        "datecol_list = ['issue_d','earliest_cr_line','last_pymnt_d','last_credit_pull_d',\n",
        "                'hardship_start_date','hardship_end_date','payment_plan_start_date',\n",
        "                'debt_settlement_flag_date','settlement_date']\n",
        "\n",
        "#loops the date columns through the dateconvert function and creates new columns with a \"2\" at the end\n",
        "for c in range(0,len(datecol_list)):\n",
        "    df[datecol_list[c]+\"2\"] = df.apply(lambda x: dateconvert(x[datecol_list[c]]), axis =1)\n",
        "    df[datecol_list[c]+\"2\"] = pd.to_datetime(df[datecol_list[c]+\"2\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZCDZUvVyatq"
      },
      "source": [
        "#### int_rate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GrqBXmtlyatq"
      },
      "source": [
        "# convert 'int_rate' to string\n",
        "df['int_rate']=df['int_rate'].astype(str)\n",
        "# strip off % sign and convert to float\n",
        "df['int_rate'] = df['int_rate'].str.rstrip('%').astype('float') / 100.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "802akcTsyatt"
      },
      "source": [
        "#### revol_util"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mMzPbmaWyatt"
      },
      "source": [
        "# convert 'revol_util' to string\n",
        "df['revol_util']=df['revol_util'].astype(str)\n",
        "# strip off % sign and convert to float\n",
        "df['revol_util'] = df['revol_util'].str.rstrip('%').astype('float') / 100.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7YjOC7d-yatw"
      },
      "source": [
        "## Feature Generation & Transformations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCvIdU7Kyatw"
      },
      "source": [
        "#### len_credit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T2FF599pyatw"
      },
      "source": [
        "#calculates the length of credit they've had in years\n",
        "df['len_credit'] = pd.to_numeric((df['issue_d2']-df['earliest_cr_line2']).dt.days)/365"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xd9Neb3kyaty"
      },
      "source": [
        "#### max_fico_high"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5KbObHZyatz"
      },
      "source": [
        "df['max_fico_high']= df[[\"fico_range_high\", \"sec_app_fico_range_high\"]].max(axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zSYNHIxEyat1"
      },
      "source": [
        "#### max_fico_low"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sMOAV3Uxyat1"
      },
      "source": [
        "df['max_fico_low']= df[[\"fico_range_low\", \"sec_app_fico_range_low\"]].max(axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZQkiIEIyat4"
      },
      "source": [
        "#### delinq_amt_pct "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HIGztWKhyat4"
      },
      "source": [
        "df['delinq_amt_pct']=(df['delinq_amnt']/df['out_prncp'])\n",
        "df.loc[df['delinq_amt_pct']> 1, 'delinq_amt_pct'] = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2hIV6S8Zyat6"
      },
      "source": [
        "#### sats_pct "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uG-QyEuGyat7"
      },
      "source": [
        "df['sats_pct']=(df['num_sats']/df['open_acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KYDPyZuQyat9"
      },
      "source": [
        "#### emp_length2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WsFA7i4nyat9"
      },
      "source": [
        "#converts employment lengt to a number (imputes 0 years for null)\n",
        "df['emp_length2'] = df['emp_length'].str[0:1]\n",
        "df.loc[df['emp_length']==\"< 1 year\", 'emp_length2'] = \"0\"\n",
        "df.loc[df['emp_length']==\"10+ years\", 'emp_length2'] = \">\"\n",
        "df.loc[df['emp_length2']==\">\", 'emp_length2'] = \"10\"\n",
        "df.loc[df['emp_length'].isnull(), 'emp_length2'] = \"0\"\n",
        "df['emp_length2']=df['emp_length2'].astype(int)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PLHiEGxXyat_"
      },
      "source": [
        "#### initial_list_status (create dummy)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nTIvl71PyauA"
      },
      "source": [
        "df.loc[df['initial_list_status']==\"w\", 'initial_list_status2'] = 0\n",
        "df.loc[df['initial_list_status']==\"f\", 'initial_list_status2'] = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TUNIRNNayauB"
      },
      "source": [
        "#### hardship_flag"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oqqy1SXOyauC"
      },
      "source": [
        "df.loc[df['hardship_flag']==\"N\", 'hardship_flag2'] = 0\n",
        "df.loc[df['hardship_flag']==\"Y\", 'hardship_flag2'] = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pAkuQS7ZyauD"
      },
      "source": [
        "#### home_ownership"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZLJcanWyauE"
      },
      "source": [
        "df['home_ownership2'] = 0\n",
        "df.loc[df['home_ownership']==\"RENT\", 'home_ownership2'] = 1\n",
        "df.loc[df['home_ownership']==\"OWN\", 'home_ownership2'] = 2\n",
        "df.loc[df['home_ownership']==\"MORTGAGE\", 'home_ownership2'] = 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uOd80rPLyauF"
      },
      "source": [
        "#### desc"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3CrmvbiByauG"
      },
      "source": [
        "df['desc2'] = 1\n",
        "df.loc[df['desc'].isnull(), 'desc2'] = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kO7GqXMYyauH"
      },
      "source": [
        "#### verification_status"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uYK2QPjFyauI"
      },
      "source": [
        "df.loc[df['verification_status']==\"Not Verified\", 'verification_status2'] = 0\n",
        "df.loc[df['verification_status']==\"Verified\", 'verification_status2'] = 1\n",
        "df.loc[df['verification_status']==\"Source Verified\", 'verification_status2'] = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5pajV9oUyauJ"
      },
      "source": [
        "#### pymnt_plan"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48YVL3biyauK"
      },
      "source": [
        "df.loc[df['pymnt_plan']==\"n\", 'pymnt_plan2'] = 0\n",
        "df.loc[df['pymnt_plan']==\"y\", 'pymnt_plan2'] = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0wOGUOg3yauN"
      },
      "source": [
        "#### default_ind"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KRhtniV0yauN"
      },
      "source": [
        "#creates binary indicator for defaulted or not\n",
        "#just an error checker to ensure that all statuses are accounted for\n",
        "df['default_ind']=2\n",
        "#should be a lsit of all good status loans\n",
        "df.loc[(df['loan_status'] == 'Fully Paid'), 'default_ind'] = 0\n",
        "#should be a list of all defaulted loans\n",
        "df.loc[(df['loan_status'] == 'Charged Off'), 'default_ind'] = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JrNZDff2yauP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4P0y0rIYyauR"
      },
      "source": [
        "## Row/bad data deletion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hz7SodnTyauR"
      },
      "source": [
        "#### convert blanks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7J4ZT6PoyauR"
      },
      "source": [
        "#convert blanks to NA\n",
        "df['dti'].replace('', np.nan, inplace=True)\n",
        "df['revol_util'].replace('', np.nan, inplace=True)\n",
        "df['tot_coll_amt'].replace('', np.nan, inplace=True)\n",
        "df['delinq_amt_pct'].replace('', np.nan, inplace=True)\n",
        "df['pct_tl_nvr_dlq'].replace('', np.nan, inplace=True)\n",
        "df['pub_rec_bankruptcies'].replace('', np.nan, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "762iPxxvyauU"
      },
      "source": [
        "#### bad dates"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ti7QlA_lyauU"
      },
      "source": [
        "#removes rows with empty dates as they were all set to 01/01/1990\n",
        "df=df[(df['issue_d2']!=\"1900-01-01\") | (df['earliest_cr_line2']!=\"1900-01-01\")]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_o-p4eQWyauW"
      },
      "source": [
        "## Modeling data set creation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFXsG4omyauW"
      },
      "source": [
        "#keep only columns we need\n",
        "modeldf = df[['id', 'default_ind', 'loan_amnt', 'term', 'int_rate', 'grade', \n",
        "              'emp_length2', 'home_ownership2', 'annual_inc', \n",
        "              'pymnt_plan2', 'desc2', 'purpose', 'dti', 'delinq_2yrs', \n",
        "              'revol_util', 'initial_list_status2', 'application_type', \n",
        "              'tot_coll_amt', 'chargeoff_within_12_mths', 'pct_tl_nvr_dlq', 'pub_rec_bankruptcies', \n",
        "              'total_bal_ex_mort', 'hardship_flag2', 'delinq_amt_pct', \n",
        "              'sats_pct', 'max_fico_low','len_credit' ]]\n",
        "\n",
        "modeldf=modeldf.dropna()\n",
        "modeldf = modeldf.reset_index(drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Br2LSs5yauX"
      },
      "source": [
        "#split into training and testing \n",
        "#needs to actually be coded in\n",
        "modeldftrain=modeldf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YaXLcMHIyauZ"
      },
      "source": [
        "#save files\n",
        "modeldftrain.to_csv('modelingdftrain.csv')  "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}